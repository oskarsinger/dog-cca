\input{../../hosinger/tex/oskar_macros.tex}

\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{bbm}
\usepackage{algorithm}
\usepackage{algorithmic}

\newtheorem{thm}{Theorem}

\begin{document}

\section{Intro} \label{sec:intro}

\subsection{Notation} \label{subsec:notation}

In the following notes, $\mbX_i \in \mbbR^{n \times p_i}$ will refer to the observation matrix for the $i$-th 'view' of some assumed underlying phenomenon, where $n$ is the number of observations and $p_i$ is the ambient dimension of the $i$-th view. $\mbPhi_i \in \mbbR^{p_i \times k}$ will refer to some linear transform of $\mbX_i$ into a $k$-dimensional space. The $k \times k$ identity matrix is denoted $\mbI_k$.

\subsection{Canonical Correlation Analysis} \label{subsec:cca}

\subsection{Generalized Eigenvalue Problems} \label{subsec:gep}

\section{Optimization} \label{sec:optimization}

	\subsection{Optimization Problem Formulation} \label{subsec:problemformulation}
	
	\subsubsection{Classical Two-View CCA} \label{subsubsec:classicalcca}
	
	This problem formulation is limited to two views, and it does not take advantage of the full power of the corresponding generalized eigenvalue problem formulation.
	
	\begin{align*}
		\tnb{minimize}&\ \ \norm{\mbX_1 \mbPhi_1 - \mbX_2 \mbPhi_2}_F^2\\
		\tnb{subject to}&\ \  \mbPhi_1^{\top}\mbX_1^{\top}\mbX_1\mbPhi_1 = \mbI_k\\
		&\ \ \mbPhi_2^{\top}\mbX_2^{\top}\mbX_2\mbPhi_2 = \mbI_k \tn{,}
	\end{align*}
	
	\noindent where $\mbPhi_1$ and $\mbPhi_2$ are the optimization variables.
	
	\subsubsection{Complete Multiview Graph} \label{subsubsec:cgraph}
	
	This problem formulation is capable of considering an arbitrary, finite number of views of the data, and it assumes the existence of non-spurious correlation between each pair of views.
	
	\begin{align*}
		\tnb{minimize}&\ \ \sum_{i=1}^m \sum_{j=i+1}^m \norm{\mbX_i \mbPhi_i - \mbX_j \mbPhi_j}_F^2\\
		\tnb{subject to}&\ \  \mbPhi_i^{\top}\mbX_i^{\top}\mbX_i\mbPhi_i = \mbI_k\ \ i=1,\ldots,m \tn{,}
	\end{align*}
	
	\noindent where $\mbPhi_i$ are the optimization variables.
	
	\subsubsection{Approximation of Complete Graph} \label{subsubsec:approxfcgraph}
	
	This problem formulation simplifies the model in section~\ref{subsubsec:cgraph} by replacing the exhaustive pairwise comparisons with $m$ comparisons to a global auxiliary variable. The idea is that the different views are related to each other via $\mbPsi$ without having to enumerate $O\fitp{m}$ penalties. However, doesn't provide much benefit in terms of the cost of computing the gradient for each $\mbPhi_i$. Also, it is not obvious to me how to reformulate this as a GEP. I am not even sure that its possible. On the other hand, $\mbPsi$ may have a meaningful and interesting interpretation as a summarizer.
	
	\begin{align*}
		\tnb{minimize}&\ \ \sum_{i=1}^m \norm{\mbX_i \mbPhi_i - \mbPsi}_F^2\\
		\tnb{subject to}&\ \  \mbPhi_i^{\top}\mbX_i^{\top}\mbX_i\mbPhi_i = \mbI_k\ \ i=1,\ldots,m \tn{,}
	\end{align*}
	
	\noindent where $\mbPhi_i$ and $\mbPsi$ are the optimization variables.

	\subsubsection{Arbitrary Dependency Graph} \label{subsubsec:arbdepgraph}
	
	This optimization problem is a good fit for a scenario in which the user has prior knowledge of which views should be correlated with each other. If this prior knowledge is close enough to correct, then using this formulation may reduce the risk of noise-dominated updates from high distances between uncorrelated views as well as discovery of spurious correlations.
	
	\begin{align*}
		\tnb{minimize}&\ \ \sum_{(i,j) \in E}\norm{\mbX_i \mbPhi_i - \mbX_j \mbPhi_j}_F^2\\
		\tnb{subject to}&\ \  \mbPhi_i^{\top}\mbX_i^{\top}\mbX_i\mbPhi_i = \mbI_k\ \ i=1,\ldots,m \tn{,}
	\end{align*}
	
	\noindent where $E$ is the set of edges in the dependency graph between the views, and $\mbPhi_i$ are the optimization variables. Note that we recover the optimization problem from section~\ref{subsubsec:cgraph} by setting $E = \fitcb{(i,j) : i \in \fitcb{1,\ldots,m-1}, j \in \fitcb{i+1, \ldots, m}}$.
	
	\subsection{Constraints} \label{subsec:constraints}
	The classical formulation of generalized eigenvalue problems including CCA is to have quadratic equality constraints $\mbX^{\top}\mbA\mbX = \mbI$ on the parameters $\mbX$ for some quadratic form $\mbA$. The purpose of these constraints is to force the parameters to counteract/reflect the scale of the data so that the model is robust to each view having dramatically different scale.
	
	\subsubsection{Issues with Equality Constraints} \label{subsubsec:issueswithequality}
	For both the classical and projected gradient algorithms for estimating CCA parameters, to satisfy the equality constraints, we are forced to orthogonalize some basis either via Gram-Schmidt orthogonalization or matrix square-roots. For batch classical and projected gradient optimization techniques, this causes scaling issues for both computation and storage. For the stochastic projected gradient algorithm, the projections onto a non-convex feasible region (a quadratic surface) result in lack of convergence guarantees and very likely slower local convergence when this is attainable. Additionally, if we want to use the transformations as dimensionality reduction on unseen data, we might consider satisfaction of equality constraints to be overfitting.
	
	If we want to improve convergence guarantees and reduce computation, but still account for and be robust to differences in scale between the two data views, it may be benificial to penalized the parameters for straying from the equality constraints rather than requiring exact constraint satisfaction on a non-convex (possibly not even locally convex) quadratic surface feasible region. In fact, when using the stochastic projected gradient algorithm, violating the equality constraints by a little bit is unavoidable because we use minibatches for projecting the parameters, but the feasible region is defined in terms of the full dataset.
	
	\subsubsection{Potential Proximal Alternatives} \label{subsubsec:alternatives}
	If we define some penality function $R(\mbX) = \norm{\mbX^{\top}\mbA\mbX - \mbI}_F^2$ and use this penalty function as a proximal function, it may result in more efficient computation and better convergence properties for parameter estimation and better generalization ability for the dimensionality reduction defined in terms of the parameters. I am somewhat certain that this function, although non-convex, has no spurious critical points. 
	
	Using $R(\mbX)$ as a proximal function is somewhat problematic because of the lack of closed-form solution. However, since we are relaxing the constraints to a soft penalty anyway, it may be acceptable to take a small, fixed number of gradient steps to approximate the proximal operator's solution at each round.
	
	Also, I need to read further to see if I can apply this and if it will be helpful, but (I think) according to \cite{parikh2014proximal}, in some cases, for a proximal operator on a matrix-valued parameter, there is some equivalent proximal operator of the parameter's singular values.
	
	\subsection{Algorithms} \label{subsec:alg}
	
	\subsubsection{Why gradients?} \label{subsubsec:whygradients}
	Gradient-based updates allow us to easily derive stochastic and mini-batch algorithms and make incremental updates where we have complete control over the scale and influence of the incremental updates. These abilities facilitate a filter-like perspective of CCA and similar problems, and since we can control the scale/influence of each incremental update, we can control the rate of change of each parameter as a function of many quantities, including the update rates of other parameters. We can use tools from online learning and online optimization to approach these problems efficiently and with strong theoretical guarantees.

	\subsubsection{Stochastic $m$-View AppGrad} \label{subsubsec:appgrad}
	
	The algorithm in this section is derived from a similar algorithm for classical two-view CCA given in \cite{ma2015finding}.
	
	\begin{algorithm}
	\caption{Stochastic $m$-view, rank-$k$ AppGrad} \label{alg:stochappgrad}
	\begin{algorithmic}[1]
		\STATE \textbf{Input:} batch size $n$, step sizes $\eta_{1t},\ldots,\eta_{mt}$, max iter $T$, num components $k$
		\STATE \textbf{Output:} Canonical bases $\fitp{\mbPhi_1, \ldots, \mbPhi_m}$
		\STATE \textbf{Initialization:} $t=0$, $\tilde{\mbPhi}_1^{(0)} \in \mbbR^{p_1 \times k}, \ldots, \tilde{\mbPhi}_m^{(0)} \in \mbbR^{p_m \times k}$ each with entries sampled invidually from $\mcN \fitp{0,1}$, $\mbPhi_j^{(0)} = \mbf{0}$ for $j = 1,\ldots,m$
		\WHILE{$t < T$ \textbf{and} not converged}
		\STATE Receive minibatch $\mbX_1^{(t)} \in \mbbR^{n \times p_1}, \ldots, \mbX_m^{(t)} \in \mbbR^{n \times p_m}$
		\FOR{$i=1, \ldots, m$}
		\STATE $\tilde{\mbPhi_j}^{(t+1)} \leftarrow \tilde{\mbPhi_i}^{(t)} - \eta_{it}\fitp{\mbX_i^{(t)}}^{\top}\fitp{(m-1)\mbX_i^{(t)}\tilde{\mbPhi}_i^{(t)} - \sum_{j \neq i}\mbX_j^{(t)}\mbPhi_j^{(t)}}$
		\STATE SVD: $\fitp{\tilde{\mbPhi_i}^{(t+1)}}^{\top} \fitp{\frac{1}{n} {\mbX_i}^{\top}\mbX_i}\tilde{\mbPhi_i}^{(t+1)} = \mbU_i^{\top}\mbD_i\mbU_i$
		\STATE $\mbPhi_i^{(t+1)} \leftarrow \tilde{\mbPhi}_i^{(t+1)}\mbU_i^{\top}\mbD_i^{-\frac{1}{2}}\mbU_i$
		\ENDFOR
		\STATE $t \leftarrow t+1$
		\ENDWHILE
	\end{algorithmic}
	\end{algorithm}
	
	\noindent \textbf{Minibatch Management:} It should be noted that the minibatches are managed by fixed-length queues to deal with different sampling rates for different views, so the pseudocode for Algorithm~\ref{alg:stochappgrad} is not entirely faithful to my implementation. I would like to eventually give more rigorous treatment of this later, possibly using some Markov chain theory.
	
	\noindent \textbf{Parameter Updates:} It should be noted that I am not making na\"{i}ve gradient updates. This is overlooked in the pseudocode for clarity and relevance reasons. I am actually applying AdaGrad scaling with optional dual averaging and shrinkage-and-thresholding to the singular values of the parameter matrix and gradient matrix \citep{duchi2011adaptive}.
	
	\subsubsection{GenELinK and CCALin} \label{subsubsec:genelinkandccalin}
	
	Algorithms~\ref{alg:genelink} and~\ref{alg:ccalin} in this section are taken directly from \cite{ge2016efficient}. Algorithms~\ref{alg:genelink-filter} and~\ref{alg:ccalin-filter} are inspired by \cite{ge2016efficient}.
	
	\begin{algorithm}
	\caption{GenELinK} \label{alg:genelink}
	\begin{algorithmic}[1]
	\STATE \textbf{Input:} $T$, $k$, symmetric matrix $\mbA$, PSD matrix $\mbB$, subroutine $\tn{GS}_{\mbB}\fitp{\cdot}$ that performs Gram-Schmidt process, with inner product $\fitab{\cdot,\cdot}_{\mbB}$
	\STATE \textbf{Output:} top $k$ eigen-space $\mbW \in \mbbR^{d \times k}$
	\STATE $\tilde{\mbW}^{(0)} \leftarrow$ random $d \times k$ matrix with each entry i.i.d. from $\mcN \fitp{0,1}$
	\STATE $\mbW^{(0)} \leftarrow \tn{GS}_{\mbB}\fitp{\tilde{\mbW}^{(0)}}$
	\FOR{$t=0,\ldots,T-1$}
	\STATE $\mbGamma^{(t)} \leftarrow \fitp{\fitp{\mbW^{(t)}}^{\top}\mbB\mbW^{(t)}}^{-1} \fitp{\fitp{\mbW^{(t)}}^{\top}\mbA\mbW^{(t)}}$
	\STATE $\tilde{\mbW}^{(t+1)} \leftarrow \argmin{\mbW} \tn{tr}\fitp{\frac{1}{2}\mbW^{\top}\mbB\mbW - \mbW^{\top}\mbA\mbW}$
	\STATE $\fitcb{\tn{Use an optimization subroutine with initialization } \mbW^{(t)}\mbGamma^{(t)}}$
	\STATE $\mbW^{(t+1)} \leftarrow \tn{GS}_{\mbB}\fitp{\tilde{\mbW}^{(t+1)}}$
	\ENDFOR
	\RETURN $\mbW^{(T)}$
	\end{algorithmic}
	\end{algorithm}
	
	\begin{algorithm}
	\caption{CCALin} \label{alg:ccalin}
	\begin{algorithmic}[1]
	\STATE \textbf{Input:} $T$, $k$, data matrix $\mbX \in \mbbR^{n \times d_1}$, $\mbY \in \mbbR^{n \times d_2}$, subroutine $\tn{GS}_{\mbM}\fitp{\cdot}$ that performs Gram-Schmidt process, with inner product $\fitab{\cdot,\cdot}_{\mbM}$ where $\mbM$ is any PSD matrix
	\STATE \textbf{Output:} top $k$ canonical subspace $\mbW_x \in \mbbR^{d_1 \times k}$, $\mbW_y \in \mbbR^{d_2 \times k}$
	\STATE $\mbS_{xx} \leftarrow \mbX^{\top}\mbX/n$, $\mbS_{yy} \leftarrow \mbY^{\top}\mbY/n$, $\mbS_{xy} \leftarrow \mbX^{\top}\mbY/n$
	\STATE $\mbA \leftarrow \fitp{\begin{array}{cc}0 & \mbS_{xy} \\ \mbS_{xy}^{\top} & 0 \end{array}}$, $\mbB \leftarrow \fitp{\begin{array}{cc}\mbS_{xx} & 0 \\ 0 & \mbS_{yy} \end{array}}$
	\STATE $\fitp{\begin{array}{cc} \bar{\mbW}_x \in \mbbR^{d_1 \times k} \\\bar{\mbW}_y \in \mbbR^{d_2 \times k} \end{array}} \leftarrow \tn{GenELinK}\fitp{\mbA,\mbB, T, k}$
	\STATE $\mbU \leftarrow 2k \times k$ random Gaussian matrix
	\STATE $\tilde{\mbW}_x \leftarrow \bar{\mbW}_x \mbU$, $\tilde{\mbW}_y \leftarrow \bar{\mbW}_y \mbU$
	\STATE $\mbW_x \leftarrow \tn{GS}_{\mbS_{xx}}\fitp{\tilde{\mbW}_x}$, $\mbW_y \leftarrow \tn{GS}_{\mbS_{yy}}\fitp{\tilde{\mbW}_y}$
	\end{algorithmic}
	\end{algorithm}
	
	\begin{algorithm}
	\caption{GenELinK Filter} \label{alg:genelink-filter}
	\begin{algorithmic}[1]
	\STATE \textbf{Initialization:} $\tilde{\mbW}^{(0)} \leftarrow$ random $d \times k$ matrix with each entry i.i.d. from $\mcN \fitp{0,1}$, $t \leftarrow 0$
	\WHILE{True}
	\STATE \textbf{Receive} symmetric matrix $\mbA^{(t)}$, PSD matrix $\mbB^{(t)}$, subroutine $\tn{GS}_{\mbB^{(t)}}\fitp{\cdot}$ that performs Gram-Schmidt process, with inner product $\fitab{\cdot,\cdot}_{\mbB^{(t)}}$
	\STATE $\mbW^{(t)} \leftarrow \tn{GS}_{\mbB^{(t)}}\fitp{\tilde{\mbW}^{(t)}}$
	\STATE $\mbGamma^{(t)} \leftarrow \fitp{\fitp{\mbW^{(t)}}^{\top}\mbB_t\mbW^{(t)}}^{-1}\fitp{\fitp{\mbW^{(t)}}^{\top}\mbA_t\mbW^{(t)}}$
	\STATE $\tilde{\mbW}^{(t+1)} \leftarrow \argmin{\mbW} \tn{tr}\fitp{\frac{1}{2}\mbW^{\top}\mbB^{(t)}\mbW - \mbW^{\top}\mbA^{(t)}\mbW}$
	\STATE $\fitcb{\tn{Use an optimization subroutine with initialization } \mbW^{(t)}\mbGamma^{(t)}}$
	\STATE $\mbW^{(t+1)} \leftarrow \tn{GS}_{\mbB^{(t)}}\fitp{\tilde{\mbW}^{(t+1)}}$
	\STATE \textbf{yield} $\mbW^{(t+1)}$
	\STATE $t \leftarrow t + 1$
	\ENDWHILE
	\end{algorithmic}
	\end{algorithm}
	
	\begin{algorithm}
	\caption{CCALin Filter} \label{alg:ccalin-filter}
	\begin{algorithmic}[1]
	\STATE \textbf{Initialization:} $t \leftarrow 0$, $\tn{GF} \fitp{\cdot, \cdot, \cdot}$ an instance of GenELinK Filter
	\WHILE{True}
	\STATE \textbf{Receive} $\mbX^{(t)} \in \mbbR^{n \times d_1}$, $\mbY^{(t)} \in \mbbR^{n \times d_2}$
	\STATE $\mbS_{xx}^{(t)} \leftarrow \fitp{\mbX^{(t)}}^{\top}\mbX^{(t)}/n$, $\mbS_{yy}^{(t)} \leftarrow \fitp{\mbY^{(t)}}^{\top}\mbY^{(t)}/n$, $\mbS_{xy}^{(t)} \leftarrow \fitp{\mbX^{(t)}}^{\top}\mbY^{(t)}/n$
	\STATE $\mbA^{(t)} \leftarrow \fitp{\begin{array}{cc}0 & \mbS_{xy}^{(t)} \\ \fitp{\mbS_{xy}^{(t)}}^{\top} & 0 \end{array}}$, $\mbB^{(t)} \leftarrow \fitp{\begin{array}{cc}\mbS_{xx}^{(t)} & 0 \\ 0 & \mbS_{yy}^{(t)} \end{array}}$
	\STATE $\fitp{\begin{array}{cc} \bar{\mbW}_x \in \mbbR^{d_1 \times k} \\\bar{\mbW}_y \in \mbbR^{d_2 \times k} \end{array}} \leftarrow \tn{GF}\fitp{\mbA^{(t)},\mbB^{(t)}, \tn{GS}_{\mbB^{(t)}}}$
	\STATE $\mbU^{(t)} \leftarrow 2k \times k$ random Gaussian matrix
	\STATE $\tilde{\mbW}_x^{(t)} \leftarrow \bar{\mbW}_x^{(t)} \mbU^{(t)}$, $\tilde{\mbW}_y^{(t)} \leftarrow \bar{\mbW}_y^{(t)} \mbU^{(t)}$
	\STATE $\mbW_x^{(t)} \leftarrow \tn{GS}_{\mbS_{xx}^{(t)}}\fitp{\tilde{\mbW}_x^{(t)}}$, $\mbW_y^{(t)} \leftarrow \tn{GS}_{\mbS_{yy}^{(t)}}\fitp{\tilde{\mbW}_y^{(t)}}$
	\STATE \textbf{yield} $\mbW_x^{(t)}$, $\mbW_y^{(t)}$
	\STATE $t \leftarrow t + 1$
	\ENDWHILE
	\end{algorithmic}
	\end{algorithm}
	
	\subsubsection{GenELinK and CCALin Filters}
	For transforming the CCA algorithm with GenELinK subroutine into an adaptive filtering algorithm, we need to ensure that two criteria are satisfied:
	
	\begin{itemize}
		\item There is an updated set of canonical bases available for filtering unseen datapoints after each minibatch is processed.
		\item State from previous parameter updates are maintained across minibatches.
	\end{itemize}
	
	\noindent To satisfy these criteria, it will likely be necessary to make a call to the GenELinK subroutine or something like it for each minibatch. There are at least two clear options aside from what is described in Algorithm~\ref{alg:genelink-filter}.
	
	\begin{itemize}
		\item Perform the full GenELinK subroutine on each minibatch and initialize each round's GenELinK with the previous round's canonical bases.
		\item For each minibatch, perform only a single stochastic gradient step on the quadratic program inside the GenELinK subroutine before giving the output back to the CCA algorithm
	\end{itemize}
	
	\subsubsection{$m$-View CCALin}
	To derive the $m$-view variation of CCALin, it should be sufficient to receive $m$ datasets $\mbX_1,\ldots,\mbX_m$ (or minibatches for the filtering scenario) and change the generation of $\mbA$ and $\mbB$ to the following
	
	\begin{align*}
		\mbA &\leftarrow \fitp{\begin{array}{cccc}0 & \mbS_{x_1 x_2} & \cdots & \mbS_{x_1 x_m} \\ \fitp{\mbS_{x_1 x_2}}^{\top} & 0 & \ddots & \vdots \\ \vdots & \ddots & \ddots & \mbS_{x_{m-1} x_m} \\ \fitp{\mbS_{x_1 x_m}}^{\top} & \cdots & \fitp{\mbS_{x_{m-1} x_m}}^{\top} & 0 \end{array}}\\
		\mbB &\leftarrow \fitp{\begin{array}{cccc}\mbS_{x_1} & 0 & \cdots & 0 \\ 0 & \ddots & \ddots & \vdots \\ \vdots & \ddots & \ddots & 0 \\ 0 & \cdots & 0 & \mbS_{x_m} \end{array}}
	\end{align*}
	
	\noindent where $\mbS_{x_i x_j} \leftarrow \mbX_i^{\top}\mbX_j/n$ and $\mbS_{x_i} \leftarrow \mbX_i^{\top}\mbX_i/n$.
	
\section{Probabilistic Models} \label{sec:probabilisticmodels}
Eventually, I would like to develop rigorous probabilistic models for each of the objective functions in section~\ref{subsec:objective}. The place to start is probably \cite{bach2005probabilistic}, which develops such a model for the optimization problem in section~\ref{subsubsec:classicalcca}. It is important to note that the resulting graphical models are not identical to the dependency graphs discussed in section~\ref{subsec:problemformulation}.

	\subsection{Classical Two-View CCA} \label{sec:classicalprob}
	
	\begin{thm}
	The maximum likelihood estimates of the parameters $W$, $\mu$ and $\sigma^2$ of the following model:
	\begin{align*}
	z\ &\sim\ \mcN \fitp{0, I_d}\\
	x|z\ &\sim\ \mcN \fitp{Wz + \mu, \sigma^2 I_m},\ \ \sigma > 0,\ \ W \in \mbbR^{m_d}
	\end{align*}
	
	\noindent are
	
	\begin{align*}
		\hat{\mu} = \tilde{\mu},\ \ \hat{W} = U_d \fitp{\Lambda_d - \sigma^2 I}^{\frac{1}{2}}R,\ \ \hat{\sigma}^2 = \frac{1}{m-d} \sum_{i=d+1}^m \lambda_i \tn{,}
	\end{align*}
	
	\noindent where the d column
	\end{thm}
	
	\bibliographystyle{apalike}
	\bibliography{../../hosinger/tex/citations.bib}
\end{document}
